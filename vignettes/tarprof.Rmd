---
title: "tarprof"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tarprof}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo=FALSE}
# Clean up previous executions
targets::tar_destroy("all", ask=FALSE)
```

We create the targets pipeline as normal:

```{r}
targets::tar_script({
  list(
    tar_target(sizes, c(10E6, 10E7, 10E8)),
    tar_target(make_vectors, numeric(sizes), pattern = map(sizes))
  )
}, ask = FALSE)
```

We need to specify a directory that will be used to save the profiling results:
```{r}
monitor_path <- file.path(getwd(), "profile_results")
```

```{r}
#| echo = FALSE
# Clean up previous outputs if they exist
list.files(monitor_path, full.names = TRUE) |> unlink()
```


When it comes to running, we pass in the custom `callr_function`.
In addition, we need to pass that function arguments using `callr_arguments`.
One of these arguments must be `monitor_path`.

```{r}
targets::tar_make(
  callr_function = tarprof::callr_profile,
  callr_arguments = list(
    monitor_path = monitor_path
  )
)
```
Note that for the moment, it is not recommended that you use any parallelism when running the pipeline in profiling mode.
In other words, when calling `crew::crew_controller_local`, use `workers = 1`.
Eventually I hope to lift this limitation.

We can access the profiling data using `profile_data`.
This returns a data frame where each row is one timepoint, and the columns correspond to various process metrics.
```{r}
tarprof::profile_data(monitor_path)
```
We can also use `memory_plot`, which connects the targets metadata with the monitoring data, allowing you to estimate the memory usage of each target.
In the plot below, each colour corresponds to a different target.
The coloured band indicates the time that `targets` thinks the target was running for (although I'm unsure how accurate this is).
The labelled point indicates the maximum memory usage for that target.
```{r}
#| fig.height = 6,
#| fig.width = 10
tarprof::memory_plot(monitor_path)
```



